{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "from copy import deepcopy\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier \n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from joblib import Parallel, delayed\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from sklearn import ensemble, linear_model, preprocessing, neighbors, datasets\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, VotingClassifier,\n",
    "                            StackingClassifier, RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (f1_score, accuracy_score, confusion_matrix, classification_report,\n",
    "                           roc_curve, auc, balanced_accuracy_score, roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets from data directory\n",
      "GPT datasets loaded successfully\n",
      "Dataset shapes:\n",
      "regular:\n",
      "  X_train: (256039, 8)\n",
      "  X_test: (53180, 8)\n",
      "  y_train: (256039,)\n",
      "  y_test: (53180,)\n",
      "\n",
      "gpt_analysis:\n",
      "  X_train: (1001, 100)\n",
      "  X_test: (1011, 100)\n",
      "  y_train: (1001,)\n",
      "  y_test: (1011,)\n",
      "\n",
      "combined_with_gpt:\n",
      "  X_train: (2000, 108)\n",
      "  X_test: (2017, 108)\n",
      "  y_train: (1001,)\n",
      "  y_test: (1011,)\n",
      "\n",
      "Regular dataset shape: (256039, 8)\n",
      "GPT dataset shape: (1001, 100)\n",
      "Combined dataset shape: (2000, 108)\n",
      "Loading datasets from data directory\n",
      "GPT datasets loaded successfully\n",
      "Dataset shapes:\n",
      "regular:\n",
      "  X_train: (256039, 8)\n",
      "  X_test: (53180, 8)\n",
      "  y_train: (256039,)\n",
      "  y_test: (53180,)\n",
      "\n",
      "gpt_analysis:\n",
      "  X_train: (1001, 100)\n",
      "  X_test: (1011, 100)\n",
      "  y_train: (1001,)\n",
      "  y_test: (1011,)\n",
      "\n",
      "combined_with_gpt:\n",
      "  X_train: (2000, 108)\n",
      "  X_test: (2017, 108)\n",
      "  y_train: (1001,)\n",
      "  y_test: (1011,)\n",
      "\n",
      "Regular dataset shape: (256039, 8)\n",
      "GPT dataset shape: (1001, 100)\n",
      "Combined dataset shape: (2000, 108)\n"
     ]
    }
   ],
   "source": [
    "#Loading regular, gpt and combined datasets\n",
    "def scale_dataset(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def process_gpt_analysis(train_texts, test_texts):\n",
    "    vectorizer = TfidfVectorizer(max_features=100) \n",
    "    X_train_tfidf = vectorizer.fit_transform(train_texts)\n",
    "    X_test_tfidf = vectorizer.transform(test_texts)\n",
    "    feature_names = [f'gpt_feature_{i}' for i in range(X_train_tfidf.shape[1])]\n",
    "    X_train_df = pd.DataFrame(X_train_tfidf.toarray(), columns=feature_names, index=train_texts.index)\n",
    "    X_test_df = pd.DataFrame(X_test_tfidf.toarray(), columns=feature_names, index=test_texts.index)\n",
    "    return X_train_df, X_test_df\n",
    "\n",
    "def load_dataset(base_path, is_target=False):\n",
    "    if is_target:\n",
    "        return pd.read_csv(base_path, index_col=0).squeeze()\n",
    "    return pd.read_csv(base_path, index_col=0)\n",
    "\n",
    "def load_all_datasets():\n",
    "    try:\n",
    "        print(\"Loading datasets from data directory\")\n",
    "        X_train = load_dataset('data/X_train.csv')\n",
    "        X_test = load_dataset('data/X_test.csv')\n",
    "        y_train = load_dataset('data/y_train.csv', is_target=True)\n",
    "        y_test = load_dataset('data/y_test.csv', is_target=True)\n",
    "        X_train_scaled, X_test_scaled = scale_dataset(X_train, X_test)\n",
    "        datasets = {'regular': (X_train_scaled, X_test_scaled, y_train, y_test)}\n",
    "        \n",
    "        try:\n",
    "            csv_params = {'engine': 'python', 'quoting': 1, 'escapechar': '\\\\', 'on_bad_lines': 'warn', \n",
    "                  'encoding': 'utf-8', 'delimiter': ',', 'quotechar': '\"', 'doublequote': True}\n",
    "            X_train_gpt = pd.read_csv('data/train_trustpilot_3_enhanced_100_X.csv', **csv_params)\n",
    "            X_test_gpt = pd.read_csv('data/test_trustpilot_3_enhanced_100_X.csv', **csv_params)\n",
    "            print(\"GPT datasets loaded successfully\")\n",
    "            train_indices = X_train_gpt.index\n",
    "            test_indices = X_test_gpt.index\n",
    "            X_train_subset = X_train_scaled.iloc[train_indices]\n",
    "            X_test_subset = X_test_scaled.iloc[test_indices]\n",
    "            y_train_subset = y_train.iloc[train_indices]\n",
    "            y_test_subset = y_test.iloc[test_indices]\n",
    "            gpt_train = X_train_gpt['gpt_analysis'].fillna(\"\")\n",
    "            gpt_test = X_test_gpt['gpt_analysis'].fillna(\"\")\n",
    "            gpt_train_processed, gpt_test_processed = process_gpt_analysis(gpt_train, gpt_test)\n",
    "            X_train_with_gpt = pd.concat([X_train_subset, gpt_train_processed], axis=1)\n",
    "            X_test_with_gpt = pd.concat([X_test_subset, gpt_test_processed], axis=1)\n",
    "            datasets.update({'gpt_analysis': (gpt_train_processed, gpt_test_processed, y_train_subset, y_test_subset), 'combined_with_gpt': (X_train_with_gpt, X_test_with_gpt, y_train_subset, y_test_subset)})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing GPT datasets: {str(e)}\")\n",
    "            print(f\"Error type: {type(e)}\") \n",
    "            print(f\"Full traceback: {traceback.format_exc()}\") \n",
    "        print(\"Dataset shapes:\")\n",
    "        for name, (X_tr, X_te, y_tr, y_te) in datasets.items():\n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  X_train: {X_tr.shape}\")\n",
    "            print(f\"  X_test: {X_te.shape}\")\n",
    "            print(f\"  y_train: {y_tr.shape}\")\n",
    "            print(f\"  y_test: {y_te.shape}\\n\")\n",
    "            \n",
    "        return datasets\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading datasets: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datasets = load_all_datasets()\n",
    "    X_train, X_test, y_train, y_test = datasets['regular']\n",
    "    print(\"Regular dataset shape:\", X_train.shape)\n",
    "    if 'gpt_analysis' in datasets:\n",
    "        X_train_gpt, X_test_gpt, y_train_gpt, y_test_gpt = datasets['gpt_analysis']\n",
    "        X_train_combined, X_test_combined, y_train_combined, y_test_combined = datasets['combined_with_gpt']\n",
    "        print(\"GPT dataset shape:\", X_train_gpt.shape)\n",
    "        print(\"Combined dataset shape:\", X_train_combined.shape)\n",
    "\n",
    "datasets = load_all_datasets()\n",
    "X_train, X_test, y_train, y_test = datasets['regular']\n",
    "print(\"Regular dataset shape:\", X_train.shape)\n",
    "if 'gpt_analysis' in datasets:\n",
    "    X_train_gpt, X_test_gpt, y_train_gpt, y_test_gpt = datasets['gpt_analysis']\n",
    "    X_train_combined, X_test_combined, y_train_combined, y_test_combined = datasets['combined_with_gpt']\n",
    "    print(\"GPT dataset shape:\", X_train_gpt.shape)\n",
    "    print(\"Combined dataset shape:\", X_train_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available datasets: ['regular', 'gpt_analysis', 'combined_with_gpt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for LogisticRegression on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5104\n",
      "Overall F1: 0.5426\n",
      "Min Class F1: 0.1866\n",
      "F1 scores per class: {0: 0.5876, 1: 0.2186, 2: 0.1866, 3: 0.2498, 4: 0.7119}\n",
      "\n",
      "Results for LogisticRegression on Regular dataset with none sampling:\n",
      "Accuracy: 0.6288\n",
      "Overall F1: 0.5205\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6299, 1: 0.0000, 2: 0.0023, 3: 0.0000, 4: 0.7805}\n",
      "\n",
      "Results for RandomForestClassifier on Regular dataset with rus sampling:\n",
      "Accuracy: 0.4801\n",
      "Overall F1: 0.5235\n",
      "Min Class F1: 0.1943\n",
      "F1 scores per class: {0: 0.5990, 1: 0.1943, 2: 0.2280, 3: 0.2382, 4: 0.6674}\n",
      "\n",
      "Results for LogisticRegression on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5114\n",
      "Overall F1: 0.5433\n",
      "Min Class F1: 0.1860\n",
      "F1 scores per class: {0: 0.5879, 1: 0.2170, 2: 0.1860, 3: 0.2491, 4: 0.7136}\n",
      "\n",
      "Results for RandomForestClassifier on Regular dataset with none sampling:\n",
      "Accuracy: 0.6245\n",
      "Overall F1: 0.5832\n",
      "Min Class F1: 0.1072\n",
      "F1 scores per class: {0: 0.6574, 1: 0.1072, 2: 0.1988, 3: 0.1558, 4: 0.8011}\n",
      "\n",
      "Results for LogisticRegression on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5111\n",
      "Overall F1: 0.5435\n",
      "Min Class F1: 0.1843\n",
      "F1 scores per class: {0: 0.5892, 1: 0.2196, 2: 0.1843, 3: 0.2514, 4: 0.7129}\n",
      "\n",
      "Results for GradientBoostingClassifier on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5271\n",
      "Overall F1: 0.5615\n",
      "Min Class F1: 0.1898\n",
      "F1 scores per class: {0: 0.6148, 1: 0.2183, 2: 0.1898, 3: 0.2593, 4: 0.7354}\n",
      "\n",
      "Results for RandomForestClassifier on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5949\n",
      "Overall F1: 0.5791\n",
      "Min Class F1: 0.1243\n",
      "F1 scores per class: {0: 0.6460, 1: 0.1243, 2: 0.2156, 3: 0.1884, 4: 0.7833}\n",
      "\n",
      "Results for RandomForestClassifier on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5511\n",
      "Overall F1: 0.5671\n",
      "Min Class F1: 0.1668\n",
      "F1 scores per class: {0: 0.6253, 1: 0.1668, 2: 0.2261, 3: 0.2333, 4: 0.7484}\n",
      "\n",
      "Results for GradientBoostingClassifier on Regular dataset with none sampling:\n",
      "Accuracy: 0.6416\n",
      "Overall F1: 0.5359\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6567, 1: 0.0000, 2: 0.0468, 3: 0.0025, 4: 0.7912}\n",
      "\n",
      "Results for GradientBoostingClassifier on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5281\n",
      "Overall F1: 0.5631\n",
      "Min Class F1: 0.1982\n",
      "F1 scores per class: {0: 0.6200, 1: 0.2212, 2: 0.1982, 3: 0.2603, 4: 0.7342}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:  33%|███▎      | 1/3 [02:07<04:14, 127.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for GradientBoostingClassifier on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5306\n",
      "Overall F1: 0.5647\n",
      "Min Class F1: 0.2021\n",
      "F1 scores per class: {0: 0.6308, 1: 0.2157, 2: 0.2021, 3: 0.2600, 4: 0.7331}\n",
      "\n",
      "Results for LogisticRegression on GPT dataset with none sampling:\n",
      "Accuracy: 0.5035\n",
      "Overall F1: 0.3419\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.0000, 1: 0.0000, 2: 0.0000, 3: 0.0284, 4: 0.6689}\n",
      "\n",
      "Results for LogisticRegression on GPT dataset with rus sampling:\n",
      "Accuracy: 0.1978\n",
      "Overall F1: 0.2214\n",
      "Min Class F1: 0.0913\n",
      "F1 scores per class: {0: 0.1626, 1: 0.0913, 2: 0.1292, 3: 0.2158, 4: 0.2803}\n",
      "\n",
      "Results for RandomForestClassifier on GPT dataset with rus sampling:\n",
      "Accuracy: 0.1701\n",
      "Overall F1: 0.1869\n",
      "Min Class F1: 0.0870\n",
      "F1 scores per class: {0: 0.2005, 1: 0.0870, 2: 0.1107, 3: 0.1596, 4: 0.2175}\n",
      "\n",
      "Results for RandomForestClassifier on GPT dataset with none sampling:\n",
      "Accuracy: 0.4857\n",
      "Overall F1: 0.3671\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.1205, 1: 0.0000, 2: 0.0182, 3: 0.0686, 4: 0.6587}\n",
      "\n",
      "Results for LogisticRegression on GPT dataset with ros sampling:\n",
      "Accuracy: 0.1850\n",
      "Overall F1: 0.2126\n",
      "Min Class F1: 0.0672\n",
      "F1 scores per class: {0: 0.1569, 1: 0.0672, 2: 0.1548, 3: 0.1386, 4: 0.2836}\n",
      "\n",
      "Results for RandomForestClassifier on GPT dataset with ros sampling:\n",
      "Accuracy: 0.4006\n",
      "Overall F1: 0.3394\n",
      "Min Class F1: 0.0478\n",
      "F1 scores per class: {0: 0.1313, 1: 0.0500, 2: 0.0576, 3: 0.0478, 4: 0.5909}\n",
      "\n",
      "Results for LogisticRegression on GPT dataset with smote sampling:\n",
      "Accuracy: 0.1889\n",
      "Overall F1: 0.2185\n",
      "Min Class F1: 0.0443\n",
      "F1 scores per class: {0: 0.1576, 1: 0.0443, 2: 0.1443, 3: 0.1808, 4: 0.2886}\n",
      "\n",
      "Results for RandomForestClassifier on GPT dataset with smote sampling:\n",
      "Accuracy: 0.3689\n",
      "Overall F1: 0.3432\n",
      "Min Class F1: 0.0533\n",
      "F1 scores per class: {0: 0.2195, 1: 0.0690, 2: 0.0533, 3: 0.0945, 4: 0.5513}\n",
      "\n",
      "Results for GradientBoostingClassifier on GPT dataset with rus sampling:\n",
      "Accuracy: 0.2097\n",
      "Overall F1: 0.2403\n",
      "Min Class F1: 0.0690\n",
      "F1 scores per class: {0: 0.1675, 1: 0.0690, 2: 0.1287, 3: 0.1824, 4: 0.3278}\n",
      "\n",
      "Results for GradientBoostingClassifier on GPT dataset with none sampling:\n",
      "Accuracy: 0.4906\n",
      "Overall F1: 0.3423\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.0189, 1: 0.0299, 2: 0.0000, 3: 0.0139, 4: 0.6626}\n",
      "\n",
      "Results for GradientBoostingClassifier on GPT dataset with ros sampling:\n",
      "Accuracy: 0.2443\n",
      "Overall F1: 0.2645\n",
      "Min Class F1: 0.1029\n",
      "F1 scores per class: {0: 0.2422, 1: 0.1029, 2: 0.1667, 3: 0.1206, 4: 0.3522}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 3/3 [02:09<00:00, 43.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for GradientBoostingClassifier on GPT dataset with smote sampling:\n",
      "Accuracy: 0.3709\n",
      "Overall F1: 0.3443\n",
      "Min Class F1: 0.0187\n",
      "F1 scores per class: {0: 0.2067, 1: 0.0187, 2: 0.0865, 3: 0.0249, 4: 0.5765}\n",
      "Error in logistic with none: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in logistic with smote: Input X contains NaN.\n",
      "SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in random_forest with none: Found input variables with inconsistent numbers of samples: [2000, 1001]\n",
      "Error in logistic with rus: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in logistic with ros: Length mismatch: Expected axis has 2655 elements, new values have 3654 elements\n",
      "Error in random_forest with smote: Input X contains NaN.\n",
      "SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in gradient_boosting with none: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in random_forest with ros: Length mismatch: Expected axis has 2655 elements, new values have 3654 elements\n",
      "Error in gradient_boosting with smote: Input X contains NaN.\n",
      "SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in gradient_boosting with ros: Length mismatch: Expected axis has 2655 elements, new values have 3654 elements\n",
      "Error in gradient_boosting with rus: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "Error in random_forest with rus: Found input variables with inconsistent numbers of samples: [1011, 2017]\n",
      "\n",
      "Average F1 scores by dataset and sampling method:\n",
      "regular with none: Overall F1 = 0.5465, Min Class F1 = 0.0357\n",
      "regular with ros: Overall F1 = 0.5618, Min Class F1 = 0.1695\n",
      "regular with rus: Overall F1 = 0.5426, Min Class F1 = 0.1902\n",
      "regular with smote: Overall F1 = 0.5584, Min Class F1 = 0.1844\n",
      "gpt_analysis with none: Overall F1 = 0.3504, Min Class F1 = 0.0000\n",
      "gpt_analysis with ros: Overall F1 = 0.2722, Min Class F1 = 0.0726\n",
      "gpt_analysis with rus: Overall F1 = 0.2162, Min Class F1 = 0.0824\n",
      "gpt_analysis with smote: Overall F1 = 0.3020, Min Class F1 = 0.0388\n",
      "\n",
      "Best Result:\n",
      "Dataset: regular\n",
      "Model: gradient_boosting\n",
      "Sampling Method: smote\n",
      "Overall F1: 0.5647\n",
      "Min Class F1: 0.2021\n",
      "Per-class F1: [0.6308420429895484, 0.21570986593331043, 0.20205894226887364, 0.2599942146369685, 0.733083582026372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Model Training & Evaluation with rebalancing:\n",
    "Regular dataset + Logistic Regression\n",
    "Regular dataset + Random Forest\n",
    "Regular dataset + Gradient Boosting\n",
    "GPT Analysis dataset + Logistic Regression\n",
    "GPT Analysis dataset + Random Forest\n",
    "GPT Analysis dataset + Gradient Boosting\n",
    "Combined dataset + Logistic Regression\n",
    "Combined dataset + Random Forest\n",
    "Combined dataset + Gradient Boosting\n",
    "\"\"\"\n",
    "\n",
    "def apply_sampling(X_train, y_train, method='none'):\n",
    "    if method == 'none':\n",
    "        return X_train, y_train\n",
    "    elif method == 'ros':\n",
    "        sampler = RandomOverSampler(random_state=25)\n",
    "    elif method == 'rus':\n",
    "        sampler = RandomUnderSampler(random_state=25)\n",
    "    elif method == 'smote':\n",
    "        sampler = SMOTE(random_state=25)\n",
    "    \n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def train_evaluate_model(model_info, X_train, X_test, y_train, y_test, sampling_method='none', current_dataset='regular'):\n",
    "    name, model = model_info\n",
    "    try:\n",
    "        X_train_sampled, y_train_sampled = apply_sampling(X_train, y_train, sampling_method)\n",
    "        if len(np.unique(y_train_sampled)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            return None\n",
    "            \n",
    "        model.fit(X_train_sampled, y_train_sampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1_per_class = f1_score(y_test, y_pred, average=None)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_overall = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        dataset_name = 'Regular dataset' if current_dataset == 'regular' else 'GPT dataset' if current_dataset == 'gpt_analysis' else 'Combined dataset'\n",
    "        print(f\"\\nResults for {model.__class__.__name__} on {dataset_name} with {sampling_method} sampling:\")\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        print(\"Overall F1: {:.4f}\".format(f1_overall))\n",
    "        print(\"Min Class F1: {:.4f}\".format(min(f1_per_class)))\n",
    "        print(\"F1 scores per class: {\" + \", \".join([f\"{k}: {v:.4f}\" for k, v in enumerate(f1_per_class)]) + \"}\")\n",
    "        \n",
    "        return {'model': name, 'sampling': sampling_method, 'f1_overall': f1_overall, 'f1_per_class': f1_per_class.tolist(), 'f1_min': float(min(f1_per_class))}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {name} with {sampling_method}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_dataset_parallel(X_train, X_test, y_train, y_test, name, n_jobs=-1):\n",
    "    models = [('logistic', LogisticRegression(random_state=25, max_iter=5000, solver='saga')),\n",
    "        ('random_forest', RandomForestClassifier(random_state=25, n_estimators=20)),\n",
    "        ('gradient_boosting', GradientBoostingClassifier(random_state=25, n_estimators=20))]\n",
    "    sampling_methods = ['none', 'ros', 'rus', 'smote']\n",
    "    all_combinations = [(model_info, sampling) \n",
    "                       for model_info in models \n",
    "                       for sampling in sampling_methods]\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(train_evaluate_model)(model_info, X_train, X_test, y_train, y_test, sampling, name)\n",
    "        for model_info, sampling in all_combinations)\n",
    "    return [r for r in results if r]\n",
    "\n",
    "def run_pipeline(datasets, n_jobs=-1):\n",
    "    results = []\n",
    "    print(\"\\nAvailable datasets:\", list(datasets.keys()))\n",
    "    with tqdm(total=len(datasets), desc=\"Processing datasets\") as pbar:\n",
    "        for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "            try:\n",
    "                dataset_results = process_dataset_parallel(X_train, X_test, y_train, y_test, name, n_jobs=n_jobs)\n",
    "                for result in dataset_results:\n",
    "                    result['dataset'] = name\n",
    "                results.extend(dataset_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {name}: {str(e)}\")\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(\"\\nAverage F1 scores by dataset and sampling method:\")\n",
    "    for name in datasets.keys():\n",
    "        for sampling in ['none', 'ros', 'rus', 'smote']:\n",
    "            dataset_sampling_results = [\n",
    "                r for r in results \n",
    "                if r['dataset'] == name and r['sampling'] == sampling]\n",
    "            if dataset_sampling_results:\n",
    "                avg_f1 = np.mean([r['f1_overall'] for r in dataset_sampling_results])\n",
    "                avg_min_f1 = np.mean([r['f1_min'] for r in dataset_sampling_results])\n",
    "                print(f\"{name} with {sampling}: Overall F1 = {avg_f1:.4f}, Min Class F1 = {avg_min_f1:.4f}\")\n",
    "    \n",
    "    if not results:\n",
    "        return {'results': [], 'best': None}\n",
    "    \n",
    "    best_result = max(results, key=lambda x: (x['f1_min'], x['f1_overall']))\n",
    "    return {'results': results, 'best': best_result}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.metrics import f1_score, accuracy_score\n",
    "    from joblib import Parallel, delayed\n",
    "    from tqdm import tqdm\n",
    "    from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    \n",
    "    results = run_pipeline(datasets, n_jobs=-1)\n",
    "    \n",
    "    if results['best']:\n",
    "        best = results['best']\n",
    "        print(f\"\\nBest Result:\")\n",
    "        print(f\"Dataset: {best['dataset']}\")\n",
    "        print(f\"Model: {best['model']}\")\n",
    "        print(f\"Sampling Method: {best['sampling']}\")\n",
    "        print(f\"Overall F1: {best['f1_overall']:.4f}\")\n",
    "        print(f\"Min Class F1: {best['f1_min']:.4f}\")\n",
    "        print(f\"Per-class F1: {best['f1_per_class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available datasets: ['regular', 'gpt_analysis', 'combined_with_gpt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for logistic_basic on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5104\n",
      "Overall F1: 0.5426\n",
      "Min Class F1: 0.1866\n",
      "F1 scores per class: {0: 0.5876, 1: 0.2186, 2: 0.1866, 3: 0.2498, 4: 0.7119}\n",
      "\n",
      "Results for logistic_basic on Regular dataset with none sampling:\n",
      "Accuracy: 0.6288\n",
      "Overall F1: 0.5205\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6299, 1: 0.0000, 2: 0.0023, 3: 0.0000, 4: 0.7805}\n",
      "\n",
      "Results for random_forest_basic on Regular dataset with rus sampling:\n",
      "Accuracy: 0.4801\n",
      "Overall F1: 0.5235\n",
      "Min Class F1: 0.1943\n",
      "F1 scores per class: {0: 0.5990, 1: 0.1943, 2: 0.2280, 3: 0.2382, 4: 0.6674}\n",
      "\n",
      "Results for logistic_basic on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5114\n",
      "Overall F1: 0.5433\n",
      "Min Class F1: 0.1860\n",
      "F1 scores per class: {0: 0.5879, 1: 0.2170, 2: 0.1860, 3: 0.2491, 4: 0.7136}\n",
      "\n",
      "Results for logistic_basic on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5111\n",
      "Overall F1: 0.5435\n",
      "Min Class F1: 0.1843\n",
      "F1 scores per class: {0: 0.5892, 1: 0.2197, 2: 0.1843, 3: 0.2513, 4: 0.7129}\n",
      "\n",
      "Results for random_forest_basic on Regular dataset with none sampling:\n",
      "Accuracy: 0.6245\n",
      "Overall F1: 0.5832\n",
      "Min Class F1: 0.1072\n",
      "F1 scores per class: {0: 0.6574, 1: 0.1072, 2: 0.1988, 3: 0.1558, 4: 0.8011}\n",
      "\n",
      "Results for gradient_boosting_basic on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5271\n",
      "Overall F1: 0.5615\n",
      "Min Class F1: 0.1898\n",
      "F1 scores per class: {0: 0.6148, 1: 0.2183, 2: 0.1898, 3: 0.2593, 4: 0.7354}\n",
      "\n",
      "Results for random_forest_basic on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5949\n",
      "Overall F1: 0.5791\n",
      "Min Class F1: 0.1243\n",
      "F1 scores per class: {0: 0.6460, 1: 0.1243, 2: 0.2156, 3: 0.1884, 4: 0.7833}\n",
      "\n",
      "Results for random_forest_basic on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5489\n",
      "Overall F1: 0.5654\n",
      "Min Class F1: 0.1678\n",
      "F1 scores per class: {0: 0.6246, 1: 0.1678, 2: 0.2208, 3: 0.2256, 4: 0.7483}\n",
      "\n",
      "Results for naive_bayes_basic on Regular dataset with none sampling:\n",
      "Accuracy: 0.5987\n",
      "Overall F1: 0.5335\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.5962, 1: 0.0000, 2: 0.1626, 3: 0.0199, 4: 0.7837}\n",
      "\n",
      "Results for naive_bayes_basic on Regular dataset with ros sampling:\n",
      "Accuracy: 0.4671\n",
      "Overall F1: 0.5054\n",
      "Min Class F1: 0.1620\n",
      "F1 scores per class: {0: 0.5322, 1: 0.2196, 2: 0.1620, 3: 0.2170, 4: 0.6737}\n",
      "\n",
      "Results for naive_bayes_basic on Regular dataset with rus sampling:\n",
      "Accuracy: 0.4643\n",
      "Overall F1: 0.5027\n",
      "Min Class F1: 0.1510\n",
      "F1 scores per class: {0: 0.5329, 1: 0.2219, 2: 0.1510, 3: 0.2213, 4: 0.6688}\n",
      "\n",
      "Results for naive_bayes_basic on Regular dataset with smote sampling:\n",
      "Accuracy: 0.4621\n",
      "Overall F1: 0.5008\n",
      "Min Class F1: 0.1354\n",
      "F1 scores per class: {0: 0.5356, 1: 0.2194, 2: 0.1354, 3: 0.2209, 4: 0.6673}\n",
      "\n",
      "Results for gradient_boosting_basic on Regular dataset with none sampling:\n",
      "Accuracy: 0.6416\n",
      "Overall F1: 0.5359\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6567, 1: 0.0000, 2: 0.0468, 3: 0.0025, 4: 0.7912}\n",
      "\n",
      "Results for logistic_bagging on Regular dataset with none sampling:\n",
      "Accuracy: 0.6288\n",
      "Overall F1: 0.5205\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6300, 1: 0.0000, 2: 0.0023, 3: 0.0000, 4: 0.7806}\n",
      "\n",
      "Results for logistic_bagging on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5088\n",
      "Overall F1: 0.5415\n",
      "Min Class F1: 0.1880\n",
      "F1 scores per class: {0: 0.5847, 1: 0.2178, 2: 0.1880, 3: 0.2521, 4: 0.7101}\n",
      "\n",
      "Results for gradient_boosting_basic on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5281\n",
      "Overall F1: 0.5631\n",
      "Min Class F1: 0.1982\n",
      "F1 scores per class: {0: 0.6200, 1: 0.2212, 2: 0.1982, 3: 0.2603, 4: 0.7342}\n",
      "\n",
      "Results for logistic_bagging on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5114\n",
      "Overall F1: 0.5434\n",
      "Min Class F1: 0.1866\n",
      "F1 scores per class: {0: 0.5878, 1: 0.2165, 2: 0.1866, 3: 0.2498, 4: 0.7136}\n",
      "\n",
      "Results for logistic_bagging on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5113\n",
      "Overall F1: 0.5437\n",
      "Min Class F1: 0.1858\n",
      "F1 scores per class: {0: 0.5888, 1: 0.2198, 2: 0.1858, 3: 0.2519, 4: 0.7130}\n",
      "\n",
      "Results for random_forest_bagging on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5143\n",
      "Overall F1: 0.5538\n",
      "Min Class F1: 0.2039\n",
      "F1 scores per class: {0: 0.6212, 1: 0.2039, 2: 0.2471, 3: 0.2568, 4: 0.7088}\n",
      "\n",
      "Results for random_forest_bagging on Regular dataset with none sampling:\n",
      "Accuracy: 0.6430\n",
      "Overall F1: 0.5825\n",
      "Min Class F1: 0.0693\n",
      "F1 scores per class: {0: 0.6742, 1: 0.0693, 2: 0.1980, 3: 0.1104, 4: 0.8098}\n",
      "\n",
      "Results for gradient_boosting_basic on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5298\n",
      "Overall F1: 0.5639\n",
      "Min Class F1: 0.1991\n",
      "F1 scores per class: {0: 0.6271, 1: 0.2172, 2: 0.1991, 3: 0.2597, 4: 0.7334}\n",
      "\n",
      "Results for random_forest_bagging on Regular dataset with ros sampling:\n",
      "Accuracy: 0.5956\n",
      "Overall F1: 0.5896\n",
      "Min Class F1: 0.1359\n",
      "F1 scores per class: {0: 0.6543, 1: 0.1359, 2: 0.2365, 3: 0.2214, 4: 0.7864}\n",
      "\n",
      "Results for svc_basic on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5119\n",
      "Overall F1: 0.5540\n",
      "Min Class F1: 0.2255\n",
      "F1 scores per class: {0: 0.5831, 1: 0.2259, 2: 0.2255, 3: 0.2687, 4: 0.7229}\n",
      "\n",
      "Results for gradient_boosting_bagging on Regular dataset with rus sampling:\n",
      "Accuracy: 0.5235\n",
      "Overall F1: 0.5598\n",
      "Min Class F1: 0.1967\n",
      "F1 scores per class: {0: 0.6127, 1: 0.2209, 2: 0.1967, 3: 0.2602, 4: 0.7310}\n",
      "\n",
      "Results for random_forest_bagging on Regular dataset with smote sampling:\n",
      "Accuracy: 0.5654\n",
      "Overall F1: 0.5811\n",
      "Min Class F1: 0.1742\n",
      "F1 scores per class: {0: 0.6391, 1: 0.1742, 2: 0.2400, 3: 0.2395, 4: 0.7654}\n",
      "\n",
      "Results for gradient_boosting_bagging on Regular dataset with none sampling:\n",
      "Accuracy: 0.6416\n",
      "Overall F1: 0.5363\n",
      "Min Class F1: 0.0000\n",
      "F1 scores per class: {0: 0.6563, 1: 0.0000, 2: 0.0529, 3: 0.0019, 4: 0.7911}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/3 [17:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m: results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m: best_result}\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    134\u001b[0m         best \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[18], line 102\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(datasets, n_jobs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, (X_train, X_test, y_train, y_test) \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         dataset_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataset_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m dataset_results:\n\u001b[1;32m    106\u001b[0m             result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n",
      "Cell \u001b[0;32mIn[18], line 86\u001b[0m, in \u001b[0;36mprocess_dataset_parallel\u001b[0;34m(X_train, X_test, y_train, y_test, name, n_jobs)\u001b[0m\n\u001b[1;32m     80\u001b[0m sampling_methods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mros\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     82\u001b[0m all_combinations \u001b[38;5;241m=\u001b[39m [(model_info, sampling) \n\u001b[1;32m     83\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m model_info \u001b[38;5;129;01min\u001b[39;00m models \n\u001b[1;32m     84\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m sampling \u001b[38;5;129;01min\u001b[39;00m sampling_methods]\n\u001b[0;32m---> 86\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_combinations\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Additional model combinations\n",
    "def apply_sampling(X_train, y_train, method='none'):\n",
    "    if method == 'none':\n",
    "        return X_train, y_train\n",
    "    elif method == 'ros':\n",
    "        sampler = RandomOverSampler(random_state=25)\n",
    "    elif method == 'rus':\n",
    "        sampler = RandomUnderSampler(random_state=25)\n",
    "    elif method == 'smote':\n",
    "        sampler = SMOTE(random_state=25)\n",
    "    return sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "def get_models():\n",
    "    base_models = {'logistic': LogisticRegression(random_state=25, max_iter=5000, solver='saga'),\n",
    "        'random_forest': RandomForestClassifier(random_state=25, n_estimators=20),\n",
    "        'gradient_boosting': GradientBoostingClassifier(random_state=25, n_estimators=20),\n",
    "        'svc': SVC(random_state=25), 'naive_bayes': GaussianNB()}\n",
    "    models = [(f\"{name}_basic\", model) for name, model in base_models.items()]\n",
    "    for name, model in base_models.items():\n",
    "        models.append((f\"{name}_bagging\", BaggingClassifier(estimator=model, random_state=25, n_estimators=10)))\n",
    "    for name, model in base_models.items():\n",
    "        if name not in ['svc', 'naive_bayes']:\n",
    "            models.append((f\"{name}_adaboost\", AdaBoostClassifier(estimator=model, random_state=25, n_estimators=10)))\n",
    "    for name, model in base_models.items():\n",
    "        models.extend([(f\"{name}_ovr\", OneVsRestClassifier(model)), (f\"{name}_ovo\", OneVsOneClassifier(model))])\n",
    "    return models\n",
    "\n",
    "def train_evaluate_model(model_info, X_train, X_test, y_train, y_test, sampling_method='none', current_dataset='regular'):\n",
    "    name, model = model_info\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_train_sampled, y_train_sampled = apply_sampling(X_train_scaled, y_train, sampling_method)\n",
    "        if len(np.unique(y_train_sampled)) < 2 or len(np.unique(y_test)) < 2:\n",
    "            return None\n",
    "        model_copy = deepcopy(model)\n",
    "        model_copy.fit(X_train_sampled, y_train_sampled)\n",
    "        y_pred = model_copy.predict(X_test_scaled)\n",
    "        f1_per_class = f1_score(y_test, y_pred, average=None)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_overall = f1_score(y_test, y_pred, average='weighted')\n",
    "        dataset_name = 'Regular dataset' if current_dataset == 'regular' else 'GPT dataset' if current_dataset == 'gpt_analysis' else 'Combined dataset'\n",
    "        print(f\"\\nResults for {name} on {dataset_name} with {sampling_method} sampling:\")\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        print(\"Overall F1: {:.4f}\".format(f1_overall))\n",
    "        print(\"Min Class F1: {:.4f}\".format(min(f1_per_class)))\n",
    "        print(\"F1 scores per class: {\" + \", \".join([f\"{k}: {v:.4f}\" for k, v in enumerate(f1_per_class)]) + \"}\")\n",
    "        return {'model': name, 'sampling': sampling_method, 'f1_overall': f1_overall,\n",
    "            'f1_per_class': f1_per_class.tolist(), 'f1_min': float(min(f1_per_class))}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {name} with {sampling_method}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_dataset_parallel(X_train, X_test, y_train, y_test, name, n_jobs=-1):\n",
    "    models = get_models()\n",
    "    sampling_methods = ['none', 'ros', 'rus', 'smote']\n",
    "    all_combinations = [(model_info, sampling) \n",
    "                       for model_info in models \n",
    "                       for sampling in sampling_methods]\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(train_evaluate_model)(model_info, X_train, X_test, y_train, y_test, sampling, name)\n",
    "        for model_info, sampling in all_combinations)\n",
    "    return [r for r in results if r]\n",
    "\n",
    "def run_pipeline(datasets, n_jobs=-1):\n",
    "    results = []\n",
    "    print(\"\\nAvailable datasets:\", list(datasets.keys()))\n",
    "    with tqdm(total=len(datasets), desc=\"Processing datasets\") as pbar:\n",
    "        for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "            try:\n",
    "                dataset_results = process_dataset_parallel(X_train, X_test, y_train, y_test, name, n_jobs=n_jobs)\n",
    "                for result in dataset_results:\n",
    "                    result['dataset'] = name\n",
    "                results.extend(dataset_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {name}: {str(e)}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"\\nResults Summary:\")\n",
    "    for name in datasets.keys():\n",
    "        print(f\"\\nDataset: {name}\")\n",
    "        for sampling in ['none', 'ros', 'rus', 'smote']:\n",
    "            dataset_sampling_results = [r for r in results \n",
    "                if r['dataset'] == name and r['sampling'] == sampling]\n",
    "            if dataset_sampling_results:\n",
    "                avg_f1 = np.mean([r['f1_overall'] for r in dataset_sampling_results])\n",
    "                avg_min_f1 = np.mean([r['f1_min'] for r in dataset_sampling_results])\n",
    "                print(f\"  {sampling:8} sampling: Overall F1 = {avg_f1:.4f}, Min Class F1 = {avg_min_f1:.4f}\")\n",
    "    if not results:\n",
    "        return {'results': [], 'best': None}\n",
    "    best_result = max(results, key=lambda x: (x['f1_min'], x['f1_overall']))\n",
    "    return {'results': results, 'best': best_result}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_pipeline(datasets, n_jobs=-1)\n",
    "    if results['best']:\n",
    "        best = results['best']\n",
    "        print(f\"\\nBest Result:\")\n",
    "        print(f\"Dataset: {best['dataset']}\")\n",
    "        print(f\"Model: {best['model']}\")\n",
    "        print(f\"Sampling Method: {best['sampling']}\")\n",
    "        print(f\"Overall F1: {best['f1_overall']:.4f}\")\n",
    "        print(f\"Min Class F1: {best['f1_min']:.4f}\")\n",
    "        print(f\"Per-class F1: {[f'{f1:.4f}' for f1 in best['f1_per_class']]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
