{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.api import anova_lm\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 3)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: unset; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_trustpilot = pd.read_csv('data/data_trustpilot_2.csv', engine='python')\n",
    "\n",
    "display(df_trustpilot.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First check\n",
    "df_trustpilot['local_date_posted'] = pd.to_datetime(df_trustpilot['local_date_posted'])\n",
    "\n",
    "print(df_trustpilot.columns)\n",
    "display(df_trustpilot.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 1 - HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split set into numeric, categorical and datetime variables\n",
    "#Provide statistical metrics for numeric variables\n",
    "\n",
    "numeric_variables = df_trustpilot.select_dtypes(include = ['int', 'float'])\n",
    "categorical_variables = df_trustpilot.select_dtypes(include=['object']) \n",
    "datetime_variables = df_trustpilot.select_dtypes(include=['datetime64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric variables\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(numeric_variables.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Numeric Variables')\n",
    "plt.show()\n",
    "\n",
    "#Based on the heatmap, the only strong correlation that exists among the numeric variables is between rating and verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEARSON AND SPEARMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson and Spearman\n",
    "\n",
    "def analyze_correlation_with_rating(column_name):\n",
    "    if column_name not in df_trustpilot.columns:\n",
    "        return f\"Error: Column '{column_name}' not found in dataframe\"\n",
    "    \n",
    "    # Calculate correlations\n",
    "    pearson_coeff, pearson_p = pearsonr(df_trustpilot['rating'], df_trustpilot[column_name])\n",
    "    spearman_coeff, spearman_p = spearmanr(df_trustpilot['rating'], df_trustpilot[column_name])\n",
    "    \n",
    "    # Format output\n",
    "    output = []\n",
    "    output.append(f\"Correlation Analysis: rating vs {column_name}\")\n",
    "    output.append(\"=\" * 50)\n",
    "    output.append(\"Hypothesis:\")\n",
    "    output.append(\"H0: The two variables are uncorrelated\")\n",
    "    output.append(\"H1: The two variables are correlated\")\n",
    "    output.append(\"\\nResults:\")\n",
    "    output.append(\"-\" * 50)\n",
    "    \n",
    "    # Pearson Analysis\n",
    "    output.append(f\"Pearson coefficient: {pearson_coeff}\")\n",
    "    if abs(pearson_coeff) < 0.1:\n",
    "        strength = \"extremely weak/negligible\"\n",
    "    elif abs(pearson_coeff) < 0.3:\n",
    "        strength = \"weak\"\n",
    "    elif abs(pearson_coeff) < 0.5:\n",
    "        strength = \"moderate\"\n",
    "    else:\n",
    "        strength = \"strong\"\n",
    "    direction = \"negative\" if pearson_coeff < 0 else \"positive\"\n",
    "    output.append(f\"Negative sign indicates an inverse relationship but as the value is {strength}, \"\n",
    "                 f\"this indicates a{strength} {direction} correlation.\")\n",
    "    \n",
    "    output.append(f\"\\nPearson p_value: {pearson_p}\")\n",
    "    if pearson_p < 0.05:\n",
    "        output.append(\"Value is smaller than the common significance level of 0.05. \"\n",
    "                     f\"This indicates that the correlation, although {strength}, is statistically significant.\")\n",
    "    else:\n",
    "        output.append(\"Value is larger than the common significance level of 0.05. \"\n",
    "                     \"This indicates that the correlation is not statistically significant.\")\n",
    "    \n",
    "    # Spearman Analysis\n",
    "    output.append(f\"\\nSpearman coefficient: {spearman_coeff}\")\n",
    "    if abs(spearman_coeff) < 0.1:\n",
    "        strength = \"extremely weak/negligible\"\n",
    "    elif abs(spearman_coeff) < 0.3:\n",
    "        strength = \"weak\"\n",
    "    elif abs(spearman_coeff) < 0.5:\n",
    "        strength = \"moderate\"\n",
    "    else:\n",
    "        strength = \"strong\"\n",
    "    output.append(f\"Negative sign indicates an inverse relationship and as the value is {strength}, \"\n",
    "                 f\"this indicates a {strength} {direction} correlation.\")\n",
    "    \n",
    "    output.append(f\"\\nSpearman p_value: {spearman_p}\")\n",
    "    if spearman_p < 0.05:\n",
    "        output.append(\"Value is smaller than the common significance level of 0.05. \"\n",
    "                     f\"This indicates that the correlation, although {strength}, is statistically significant.\")\n",
    "    else:\n",
    "        output.append(\"Value is larger than the common significance level of 0.05. \"\n",
    "                     \"This indicates that the correlation is not statistically significant.\")\n",
    "    \n",
    "    # Conclusion\n",
    "    output.append(\"\\nConclusion:\")\n",
    "    output.append(\"-\" * 50)\n",
    "    if pearson_p < 0.05 or spearman_p < 0.05:\n",
    "        output.append(\"H0 is rejected\")\n",
    "        output.append(\"H1 is confirmed\")\n",
    "    else:\n",
    "        output.append(\"Failed to reject H0\")\n",
    "        \n",
    "    # Additional insights\n",
    "    if abs(abs(spearman_coeff) - abs(pearson_coeff)) > 0.1:\n",
    "        output.append(f\"\\nThe difference between Pearson ({pearson_coeff:.3f}) and \"\n",
    "                     f\"Spearman ({spearman_coeff:.3f}) suggests a non-linear relationship\")\n",
    "    \n",
    "    # Practical interpretation\n",
    "    output.append(f\"\\nAs {column_name} increases, ratings tend to \"\n",
    "                 f\"{'decrease' if pearson_coeff < 0 else 'increase'}\")\n",
    "    output.append(\"While statistically significant, the relationship is \"\n",
    "                 f\"{strength}\")\n",
    "    output.append(\"Keep for model training of a rating model\")\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "# Usage\n",
    "print(analyze_correlation_with_rating('days_between_experience_and_post'))\n",
    "\n",
    "# Get list of numeric columns excluding 'rating'\n",
    "numeric_columns = df_trustpilot.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_columns = [col for col in numeric_columns if col != 'rating']\n",
    "\n",
    "print(\"Starting correlation analysis for all numeric variables...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Loop through each numeric column\n",
    "for column in numeric_columns:\n",
    "    display(HTML(f\"<pre>{analyze_correlation_with_rating(column)}</pre>\"))\n",
    "    display(HTML(\"<hr>\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA\n",
    "\n",
    "def analyze_anova_with_rating(df):\n",
    "    # Get numeric columns except rating\n",
    "    attributes = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    attributes = [col for col in attributes if col != 'rating']\n",
    "    \n",
    "    # Store results and selected features\n",
    "    results = {}\n",
    "    feat_select = []\n",
    "    \n",
    "    print(\"ANOVA Analysis: Features vs Rating\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analyze each feature\n",
    "    for feature in attributes:\n",
    "        try:\n",
    "            # Perform ANOVA\n",
    "            lm = ols('rating ~ {}'.format(feature), data=df).fit()\n",
    "            table = anova_lm(lm)\n",
    "            p_value = table['PR(>F)'].iloc[0]\n",
    "            \n",
    "            # If significant, add to selected features\n",
    "            if p_value <= 0.05:\n",
    "                feat_select.append(feature)\n",
    "                results[feature] = p_value\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {feature}: {str(e)}\")\n",
    "    \n",
    "    # Create and display results table\n",
    "    if feat_select:\n",
    "        results_df = pd.DataFrame({\n",
    "            'Feature': feat_select,\n",
    "            'P-value': [results[f] for f in feat_select]\n",
    "        }).sort_values('P-value')\n",
    "        \n",
    "        print(\"\\nSelected Features (p ≤ 0.05):\")\n",
    "        print(results_df)\n",
    "    \n",
    "    return feat_select\n",
    "\n",
    "# Usage:\n",
    "selected_features = analyze_anova_with_rating(df_trustpilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA \n",
    "\n",
    "def analyze_anova_with_rating(df):\n",
    "    attributes = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    attributes = [col for col in attributes if col != 'rating']\n",
    "    \n",
    "    results = {}\n",
    "    feat_select = []\n",
    "    output_text = []\n",
    "    \n",
    "    output_text.append(\"ANOVA Analysis: Features vs Rating\")\n",
    "    output_text.append(\"=\" * 50)\n",
    "    \n",
    "    for feature in attributes:\n",
    "        try:\n",
    "            lm = ols('rating ~ {}'.format(feature), data=df).fit()\n",
    "            table = anova_lm(lm)\n",
    "            p_value = table['PR(>F)'].iloc[0]\n",
    "            f_stat = table['F'].iloc[0]\n",
    "            \n",
    "            # Calculate effect size (eta-squared)\n",
    "            ss_between = table['sum_sq'][0]\n",
    "            ss_total = ss_between + table['sum_sq'][1]\n",
    "            eta_squared = ss_between / ss_total\n",
    "            \n",
    "            # Store results\n",
    "            results[feature] = {\n",
    "                'p_value': p_value,\n",
    "                'f_stat': f_stat,\n",
    "                'eta_squared': eta_squared\n",
    "            }\n",
    "            \n",
    "            # Interpret effect size\n",
    "            if eta_squared < 0.01:\n",
    "                effect_strength = \"negligible\"\n",
    "            elif eta_squared < 0.06:\n",
    "                effect_strength = \"small\"\n",
    "            elif eta_squared < 0.14:\n",
    "                effect_strength = \"medium\"\n",
    "            else:\n",
    "                effect_strength = \"large\"\n",
    "            \n",
    "            # Feature selection\n",
    "            if p_value <= 0.05:\n",
    "                feat_select.append(feature)\n",
    "            \n",
    "            # Output for each feature\n",
    "            output_text.append(f\"\\nAnalysis for: {feature}\")\n",
    "            output_text.append(\"-\" * 30)\n",
    "            output_text.append(f\"F-statistic: {f_stat:.4f}\")\n",
    "            output_text.append(f\"P-value: {p_value:.4e}\")\n",
    "            output_text.append(f\"Effect size (η²): {eta_squared:.4f}\")\n",
    "            output_text.append(f\"Effect strength: {effect_strength}\")\n",
    "            output_text.append(f\"Selected for model: {'Yes' if p_value <= 0.05 else 'No'}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            output_text.append(f\"\\nError analyzing {feature}: {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    output_text.append(\"\\n\" + \"=\" * 50)\n",
    "    output_text.append(\"\\nSummary:\")\n",
    "    output_text.append(f\"Total features analyzed: {len(attributes)}\")\n",
    "    output_text.append(f\"Features selected: {len(feat_select)}\")\n",
    "    output_text.append(\"\\nSelected features:\")\n",
    "    for feat in feat_select:\n",
    "        p_value = results[feat]['p_value']\n",
    "        eta = results[feat]['eta_squared']\n",
    "        output_text.append(f\"- {feat}: p={p_value:.4e}, η²={eta:.4f}\")\n",
    "    \n",
    "    print(\"\\n\".join(output_text))\n",
    "    return results, feat_select\n",
    "\n",
    "# Usage:\n",
    "results, selected_features = analyze_anova_with_rating(df_trustpilot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION WITH RIB RATIO STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with rib ratio study\n",
    "\n",
    "\n",
    "def analyze_variable_importance(column_name):\n",
    "    if column_name not in df_trustpilot.columns:\n",
    "        return f\"Error: Column '{column_name}' not found in dataframe\"\n",
    "    \n",
    "    y = (df_trustpilot['rating'] >= 4).astype(int)\n",
    "    \n",
    "    X = df_trustpilot[column_name]\n",
    "    \n",
    "    if not np.issubdtype(X.dtype, np.number):\n",
    "        return f\"Error: Column '{column_name}' is not numeric. Please encode categorical variables first.\"\n",
    "    \n",
    "    X = X.values.reshape(-1, 1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit logistic regression\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Calculate correlation (point biserial for binary vs continuous)\n",
    "    correlation, p_value = stats.pointbiserialr(y, X.ravel())\n",
    "    \n",
    "    output = []\n",
    "    output.append(f\"Variable Importance Analysis: {column_name} vs High/Low Rating\")\n",
    "    output.append(\"=\" * 60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    output.append(\"\\nBasic Statistics:\")\n",
    "    output.append(f\"Mean value for low ratings: {X[y==0].mean():.3f}\")\n",
    "    output.append(f\"Mean value for high ratings: {X[y==1].mean():.3f}\")\n",
    "    output.append(f\"Correlation coefficient: {correlation:.3f}\")\n",
    "    output.append(f\"P-value: {p_value:.3e}\")\n",
    "    \n",
    "    # Logistic Regression Results\n",
    "    output.append(\"\\nLogistic Regression Results:\")\n",
    "    output.append(f\"Coefficient: {model.coef_[0][0]:.3f}\")\n",
    "    output.append(f\"Intercept: {model.intercept_[0]:.3f}\")\n",
    "    output.append(f\"ROC AUC Score: {roc_auc:.3f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    output.append(\"\\nClassification Report:\")\n",
    "    output.append(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Effect interpretation\n",
    "    output.append(\"\\nInterpretation:\")\n",
    "    if abs(correlation) < 0.1:\n",
    "        strength = \"negligible\"\n",
    "    elif abs(correlation) < 0.3:\n",
    "        strength = \"weak\"\n",
    "    elif abs(correlation) < 0.5:\n",
    "        strength = \"moderate\"\n",
    "    else:\n",
    "        strength = \"strong\"\n",
    "    \n",
    "    direction = \"positive\" if correlation > 0 else \"negative\"\n",
    "    \n",
    "    output.append(f\"- The relationship is {strength} and {direction}\")\n",
    "    if p_value < 0.05:\n",
    "        output.append(\"- The relationship is statistically significant\")\n",
    "        output.append(f\"- As {column_name} increases, the likelihood of a high rating\")\n",
    "        output.append(f\"  {'increases' if correlation > 0 else 'decreases'}\")\n",
    "    else:\n",
    "        output.append(\"- The relationship is not statistically significant\")\n",
    "    \n",
    "    output.append(f\"- The model has an ROC AUC of {roc_auc:.3f}, indicating\")\n",
    "    if roc_auc < 0.6:\n",
    "        output.append(\"  poor predictive power\")\n",
    "    elif roc_auc < 0.7:\n",
    "        output.append(\"  fair predictive power\")\n",
    "    elif roc_auc < 0.8:\n",
    "        output.append(\"  good predictive power\")\n",
    "    else:\n",
    "        output.append(\"  excellent predictive power\")\n",
    "    \n",
    "    output.append(\"\\nKeep for model training: \")\n",
    "    output.append(\"Yes\" if (p_value < 0.05 and roc_auc > 0.6) else \"Consider dropping\")\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "# Get numeric columns excluding rating\n",
    "numeric_columns = df_trustpilot.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_columns = [col for col in numeric_columns if col != 'rating']\n",
    "\n",
    "print(\"Starting variable importance analysis...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Loop through each numeric column\n",
    "for column in numeric_columns:\n",
    "    display(HTML(f\"<pre>{analyze_variable_importance(column)}</pre>\"))\n",
    "    display(HTML(\"<hr>\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
