{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: unset; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.api import anova_lm\n",
    "from IPython.display import display, HTML\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: unset; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>username</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>verification</th>\n",
       "      <th>repeat_reviewer</th>\n",
       "      <th>repeat_reviewer_encoded</th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_length</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>Sentiment_Blob_cat</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_VADER_cat</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_processed</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>subject_word_length</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_processed</th>\n",
       "      <th>answered_encoded</th>\n",
       "      <th>date_of_experience</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>local_date_posted</th>\n",
       "      <th>month_local</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_week_posted</th>\n",
       "      <th>day_type</th>\n",
       "      <th>days_between_experience_and_post</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_time_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Rob Crane</td>\n",
       "      <td>2</td>\n",
       "      <td>Redirected</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>The company rep I worked with made my transact...</td>\n",
       "      <td>company rep worked made transaction smooth qui...</td>\n",
       "      <td>110</td>\n",
       "      <td>15</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>4</td>\n",
       "      <td>The company rep I worked with made myâ€¦</td>\n",
       "      <td>company rep worked made</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>2024-10-23 04:17:44</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>129</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Pat Anderson</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I highly recommend using Flashbay. Immediately...</td>\n",
       "      <td>highly recommend using flashbay immediately or...</td>\n",
       "      <td>202</td>\n",
       "      <td>26</td>\n",
       "      <td>0.345417</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>5</td>\n",
       "      <td>I highly recommend using Flashbay</td>\n",
       "      <td>highly recommend using flashbay</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>2024-10-16 19:34:05</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>2</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>CZ</td>\n",
       "      <td>Margarita Orlova</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had the pleasure of working with Shelby Gibs...</td>\n",
       "      <td>pleasure working shelby gibson large order nee...</td>\n",
       "      <td>175</td>\n",
       "      <td>24</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>5</td>\n",
       "      <td>Great customer service</td>\n",
       "      <td>great customer service</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>2024-10-17 10:27:44</td>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>3</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>7</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Paola Rivas</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had a fantastic experience with Brian Truong...</td>\n",
       "      <td>fantastic experience brian truong attentive tr...</td>\n",
       "      <td>122</td>\n",
       "      <td>14</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>5</td>\n",
       "      <td>Outstanding Support and Attentive Service</td>\n",
       "      <td>outstanding support attentive service</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>2024-10-21 22:38:50</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Fiona Mckelvey Keenan</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>My number-one go-to for computer accessories. ...</td>\n",
       "      <td>numberone goto computer accessories rachel sup...</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>5</td>\n",
       "      <td>My number-one go-to for computerâ€¦</td>\n",
       "      <td>numberone goto computer</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-11</td>\n",
       "      <td>2024-10-23 04:09:05</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>103</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating location               username  number_reviews  verification  \\\n",
       "0       5       CA              Rob Crane               2    Redirected   \n",
       "1       5       US           Pat Anderson               1      Verified   \n",
       "2       5       CZ       Margarita Orlova               1      Verified   \n",
       "3       5       US            Paola Rivas               1      Verified   \n",
       "4       5       CA  Fiona Mckelvey Keenan               3  Not Verified   \n",
       "\n",
       "  repeat_reviewer  repeat_reviewer_encoded   company  \\\n",
       "0          repeat                        1  Flashbay   \n",
       "1        one-time                        0  Flashbay   \n",
       "2        one-time                        0  Flashbay   \n",
       "3        one-time                        0  Flashbay   \n",
       "4          repeat                        1  Flashbay   \n",
       "\n",
       "                                                text  \\\n",
       "0  The company rep I worked with made my transact...   \n",
       "1  I highly recommend using Flashbay. Immediately...   \n",
       "2  I had the pleasure of working with Shelby Gibs...   \n",
       "3  I had a fantastic experience with Brian Truong...   \n",
       "4  My number-one go-to for computer accessories. ...   \n",
       "\n",
       "                                      text_processed  text_length  \\\n",
       "0  company rep worked made transaction smooth qui...          110   \n",
       "1  highly recommend using flashbay immediately or...          202   \n",
       "2  pleasure working shelby gibson large order nee...          175   \n",
       "3  fantastic experience brian truong attentive tr...          122   \n",
       "4  numberone goto computer accessories rachel sup...          155   \n",
       "\n",
       "   text_word_length  Sentiment_Blob  Sentiment_Blob_cat  Sentiment_VADER  \\\n",
       "0                15        0.311111                 4.0           0.4215   \n",
       "1                26        0.345417                 4.0           0.6233   \n",
       "2                24        0.320223                 4.0           0.9643   \n",
       "3                14        0.600000                 4.0           0.9169   \n",
       "4                18        0.386667                 4.0           0.8553   \n",
       "\n",
       "   Sentiment_VADER_cat                                    subject  \\\n",
       "0                    4     The company rep I worked with made myâ€¦   \n",
       "1                    5          I highly recommend using Flashbay   \n",
       "2                    5                     Great customer service   \n",
       "3                    5  Outstanding Support and Attentive Service   \n",
       "4                    5          My number-one go-to for computerâ€¦   \n",
       "\n",
       "                       subject_processed  subject_length  subject_word_length  \\\n",
       "0                company rep worked made              23                    4   \n",
       "1        highly recommend using flashbay              31                    4   \n",
       "2                 great customer service              22                    3   \n",
       "3  outstanding support attentive service              37                    4   \n",
       "4                numberone goto computer              23                    3   \n",
       "\n",
       "  answer answer_processed  answered_encoded date_of_experience  \\\n",
       "0      0                0                 0         2024-06-15   \n",
       "1      0                0                 0         2024-10-16   \n",
       "2      0                0                 0         2024-10-10   \n",
       "3      0                0                 0         2024-10-21   \n",
       "4      0                0                 0         2024-07-11   \n",
       "\n",
       "           date_posted local_date_posted  month_local  local_hour  \\\n",
       "0  2024-10-23 04:17:44        2024-10-22           10          21   \n",
       "1  2024-10-16 19:34:05        2024-10-16           10          12   \n",
       "2  2024-10-17 10:27:44        2024-10-17           10          10   \n",
       "3  2024-10-21 22:38:50        2024-10-21           10          15   \n",
       "4  2024-10-23 04:09:05        2024-10-22           10          21   \n",
       "\n",
       "      time_of_day  day_of_week_posted      day_type  \\\n",
       "0         Evening                   1  Business Day   \n",
       "1  Business Hours                   2  Business Day   \n",
       "2  Business Hours                   3  Business Day   \n",
       "3  Business Hours                   0  Business Day   \n",
       "4         Evening                   1  Business Day   \n",
       "\n",
       "   days_between_experience_and_post   review_time  review_time_encoded  \n",
       "0                               129   late_review                    0  \n",
       "1                                 0  quick_review                    1  \n",
       "2                                 7   late_review                    0  \n",
       "3                                 0  quick_review                    1  \n",
       "4                               103   late_review                    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_trustpilot = pd.read_csv('data/data_trustpilot_2.csv', engine='python')\n",
    "\n",
    "display(df_trustpilot.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values 1:  209\n",
      "Null values 2:  0\n",
      "Duplicates:  0\n",
      "Index(['rating', 'location', 'username', 'number_reviews', 'verification',\n",
      "       'repeat_reviewer', 'repeat_reviewer_encoded', 'company', 'text',\n",
      "       'text_processed', 'text_length', 'text_word_length', 'Sentiment_Blob',\n",
      "       'Sentiment_Blob_cat', 'Sentiment_VADER', 'Sentiment_VADER_cat',\n",
      "       'subject', 'subject_processed', 'subject_length', 'subject_word_length',\n",
      "       'answer', 'answer_processed', 'answered_encoded', 'date_of_experience',\n",
      "       'date_posted', 'local_date_posted', 'month_local', 'local_hour',\n",
      "       'time_of_day', 'day_of_week_posted', 'day_type',\n",
      "       'days_between_experience_and_post', 'review_time',\n",
      "       'review_time_encoded'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64205 entries, 0 to 64413\n",
      "Data columns (total 34 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   rating                            64205 non-null  int64         \n",
      " 1   location                          64205 non-null  object        \n",
      " 2   username                          64205 non-null  object        \n",
      " 3   number_reviews                    64205 non-null  int64         \n",
      " 4   verification                      64205 non-null  object        \n",
      " 5   repeat_reviewer                   64205 non-null  object        \n",
      " 6   repeat_reviewer_encoded           64205 non-null  int64         \n",
      " 7   company                           64205 non-null  object        \n",
      " 8   text                              64205 non-null  object        \n",
      " 9   text_processed                    64205 non-null  object        \n",
      " 10  text_length                       64205 non-null  int64         \n",
      " 11  text_word_length                  64205 non-null  int64         \n",
      " 12  Sentiment_Blob                    64205 non-null  float64       \n",
      " 13  Sentiment_Blob_cat                64205 non-null  float64       \n",
      " 14  Sentiment_VADER                   64205 non-null  float64       \n",
      " 15  Sentiment_VADER_cat               64205 non-null  int64         \n",
      " 16  subject                           64205 non-null  object        \n",
      " 17  subject_processed                 64205 non-null  object        \n",
      " 18  subject_length                    64205 non-null  int64         \n",
      " 19  subject_word_length               64205 non-null  int64         \n",
      " 20  answer                            64205 non-null  object        \n",
      " 21  answer_processed                  64205 non-null  object        \n",
      " 22  answered_encoded                  64205 non-null  int64         \n",
      " 23  date_of_experience                64205 non-null  datetime64[ns]\n",
      " 24  date_posted                       64205 non-null  datetime64[ns]\n",
      " 25  local_date_posted                 64205 non-null  datetime64[ns]\n",
      " 26  month_local                       64205 non-null  int64         \n",
      " 27  local_hour                        64205 non-null  int64         \n",
      " 28  time_of_day                       64205 non-null  object        \n",
      " 29  day_of_week_posted                64205 non-null  int64         \n",
      " 30  day_type                          64205 non-null  object        \n",
      " 31  days_between_experience_and_post  64205 non-null  int64         \n",
      " 32  review_time                       64205 non-null  object        \n",
      " 33  review_time_encoded               64205 non-null  int64         \n",
      "dtypes: datetime64[ns](3), float64(3), int64(14), object(14)\n",
      "memory usage: 17.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First check\n",
    "df_trustpilot['local_date_posted'] = pd.to_datetime(df_trustpilot['local_date_posted'])\n",
    "df_trustpilot['date_of_experience'] = pd.to_datetime(df_trustpilot['date_of_experience'])\n",
    "df_trustpilot['date_posted'] = pd.to_datetime(df_trustpilot['date_posted'])\n",
    "print(\"Null values 1: \", df_trustpilot.isna().sum().sum())\n",
    "df_trustpilot = df_trustpilot.dropna(how='any')\n",
    "print(\"Null values 2: \", df_trustpilot.isna().sum().sum())\n",
    "print(\"Duplicates: \", df_trustpilot.duplicated().sum())\n",
    "\n",
    "print(df_trustpilot.columns)\n",
    "display(df_trustpilot.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 1 - TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 51364\n",
      "Test set size: 12841\n",
      "Rating distribution in original data:\n",
      "rating\n",
      "5    0.489\n",
      "1    0.248\n",
      "4    0.098\n",
      "3    0.097\n",
      "2    0.067\n",
      "Name: proportion, dtype: float64\n",
      "Rating distribution in training set:\n",
      "rating\n",
      "5    0.489\n",
      "1    0.248\n",
      "4    0.098\n",
      "3    0.097\n",
      "2    0.067\n",
      "Name: proportion, dtype: float64\n",
      "Rating distribution in test set:\n",
      "rating\n",
      "5    0.489\n",
      "1    0.248\n",
      "4    0.098\n",
      "3    0.098\n",
      "2    0.067\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Splitting data with stratification on rating to make sure that ratings are distributed evenly across both sets due to data imbalance\n",
    "train_df, test_df = train_test_split(df_trustpilot, test_size=0.2,  \n",
    "    random_state=42, stratify=df_trustpilot['rating'])\n",
    "\n",
    "print(\"Training set size:\", len(train_df))\n",
    "print(\"Test set size:\", len(test_df))\n",
    "\n",
    "# Verifying rating distribution\n",
    "print(\"Rating distribution in original data:\")\n",
    "print(df_trustpilot['rating'].value_counts(normalize=True).round(3))\n",
    "print(\"Rating distribution in training set:\")\n",
    "print(train_df['rating'].value_counts(normalize=True).round(3))\n",
    "print(\"Rating distribution in test set:\")\n",
    "print(test_df['rating'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 2 - HANDLE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_reviews training outliers: 5242 (10.21%)\n",
      "days_between_experience_and_post training outliers: 14062 (27.38%)\n",
      "text_length training outliers: 3641 (7.09%)\n",
      "text_word_length training outliers: 3660 (7.13%)\n",
      "subject_length training outliers: 2019 (3.93%)\n",
      "subject_word_length training outliers: 5303 (10.32%)\n",
      "number_reviews test outliers handled: 0 (0.00%)\n",
      "days_between_experience_and_post test outliers handled: 0 (0.00%)\n",
      "text_length test outliers handled: 0 (0.00%)\n",
      "text_word_length test outliers handled: 0 (0.00%)\n",
      "subject_length test outliers handled: 0 (0.00%)\n",
      "subject_word_length test outliers handled: 0 (0.00%)\n",
      "Checking for remaining outliers:\n",
      "number_reviews: No outliers remain in training set\n",
      "number_reviews: No outliers remain in test set\n",
      "days_between_experience_and_post: No outliers remain in training set\n",
      "days_between_experience_and_post: No outliers remain in test set\n",
      "text_length: No outliers remain in training set\n",
      "text_length: No outliers remain in test set\n",
      "text_word_length: No outliers remain in training set\n",
      "text_word_length: No outliers remain in test set\n",
      "subject_length: No outliers remain in training set\n",
      "subject_length: No outliers remain in test set\n",
      "subject_word_length: No outliers remain in training set\n",
      "subject_word_length: No outliers remain in test set\n"
     ]
    }
   ],
   "source": [
    "# Handle outliers on numeric columns that make sense\n",
    "numeric_cols = ['number_reviews', 'days_between_experience_and_post',\n",
    "                'text_length', 'text_word_length', 'subject_length', \n",
    "                'subject_word_length']\n",
    "\n",
    "bounds = {}\n",
    "\n",
    "# First pass: Calculate bounds from training data and handle training set outliers\n",
    "for col in numeric_cols:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    bounds[col] = {'lower': lower_bound, 'upper': upper_bound}\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)]\n",
    "    print(f\"{col} training outliers: {len(outliers)} ({(len(outliers)/len(train_df)*100):.2f}%)\")\n",
    "    \n",
    "    # Clip training data\n",
    "    train_df[col] = train_df[col].clip(lower_bound, upper_bound)\n",
    "\n",
    "# Second pass: Handle test set outliers using bounds from training data\n",
    "for col in numeric_cols:\n",
    "    test_df[col] = test_df[col].clip(bounds[col]['lower'], bounds[col]['upper'])\n",
    "    \n",
    "    test_outliers = test_df[(test_df[col] < bounds[col]['lower']) | (test_df[col] > bounds[col]['upper'])]\n",
    "    print(f\"{col} test outliers handled: {len(test_outliers)} ({(len(test_outliers)/len(test_df)*100):.2f}%)\")\n",
    "\n",
    "#Evaluation to check output\n",
    "print(\"Checking for remaining outliers:\")\n",
    "for col in numeric_cols:\n",
    "    train_outliers = train_df[(train_df[col] < bounds[col]['lower']) | \n",
    "                             (train_df[col] > bounds[col]['upper'])]\n",
    "    if len(train_outliers) > 0:\n",
    "        print(f\"Warning: {col} still has {len(train_outliers)} outliers in training set\")\n",
    "    else:\n",
    "        print(f\"{col}: No outliers remain in training set\")\n",
    "    \n",
    "    test_outliers = test_df[(test_df[col] < bounds[col]['lower']) | \n",
    "                           (test_df[col] > bounds[col]['upper'])]\n",
    "    if len(test_outliers) > 0:\n",
    "        print(f\"Warning: {col} still has {len(test_outliers)} outliers in test set\")\n",
    "    else:\n",
    "        print(f\"{col}: No outliers remain in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 3 - ADVANCED TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 5000\n",
      "Top 10 most important n-grams:\n",
      "       feature   importance\n",
      "3367   quicken  1340.168142\n",
      "1926     great  1256.186203\n",
      "3846   service  1243.657594\n",
      "1024  customer  1016.503301\n",
      "4629       use   997.587679\n",
      "3245   product   984.166246\n",
      "2912     order   929.658261\n",
      "4393      time   883.214164\n",
      "1330      easy   854.451806\n",
      "351       asda   799.896001\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF with unigrams and bigrams\n",
    "\n",
    "def process_and_save_tfidf(train_df, test_df):\n",
    "    tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2),\n",
    "    max_df=0.8, min_df=5)\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_tfidf = tfidf.fit_transform(train_df['text_processed'])\n",
    "    X_test_tfidf = tfidf.transform(test_df['text_processed'])\n",
    "    # Get feature names (top n-grams)\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "    np.save('data/X_train_tfidf.npy', X_train_tfidf.toarray())\n",
    "    np.save('data/X_test_tfidf.npy', X_test_tfidf.toarray())\n",
    "    np.save('data/tfidf_features.npy', tfidf.get_feature_names_out())\n",
    "\n",
    "    print(f\"Number of features: {len(feature_names)}\")\n",
    "\n",
    "    feature_importance = pd.DataFrame({'feature': feature_names,\n",
    "        'importance': X_train_tfidf.sum(axis=0).A1}).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"Top 10 most important n-grams:\")\n",
    "    print(feature_importance.head(10))\n",
    "\n",
    "    return {'tfidf_train_matrix': X_train_tfidf, 'tfidf_test_matrix': X_test_tfidf,\n",
    "        'tfidf_features': feature_names}\n",
    "\n",
    "results = process_and_save_tfidf(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 5000\n",
      "Bag of Words Matrix Shape: (51364, 5000)\n",
      "Memory Usage: 0.01 GB\n"
     ]
    }
   ],
   "source": [
    "#Bag-of-Words\n",
    "\n",
    "# Bag of Words processing\n",
    "def process_and_save_bow(train_df, test_df):\n",
    "    count_vec = CountVectorizer(max_features=5000, ngram_range=(1, 2),\n",
    "                               max_df=0.8, min_df=5)\n",
    "    \n",
    "    # Fit and transform training data, only transform test data\n",
    "    X_train_bow = count_vec.fit_transform(train_df['text_processed'])\n",
    "    X_test_bow = count_vec.transform(test_df['text_processed'])\n",
    "    \n",
    "    # Get feature names (vocabulary)\n",
    "    feature_names = count_vec.get_feature_names_out()\n",
    "    \n",
    "    # Save the matrices and features\n",
    "    np.save('data/X_train_bow.npy', X_train_bow.toarray())\n",
    "    np.save('data/X_test_bow.npy', X_test_bow.toarray())\n",
    "    np.save('data/bow_features.npy', feature_names)\n",
    "    \n",
    "    print(f\"Number of features: {len(feature_names)}\")\n",
    "    print(f\"Bag of Words Matrix Shape: {X_train_bow.shape}\")\n",
    "    print(f\"Memory Usage: {X_train_bow.data.nbytes / (1024 ** 3):.2f} GB\")\n",
    "    \n",
    "    return {'X_train_bow': X_train_bow,'X_test_bow': X_test_bow,'feature_names': feature_names}\n",
    "\n",
    "results = process_and_save_bow(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rating', 'location', 'username', 'number_reviews', 'verification',\n",
      "       'repeat_reviewer', 'repeat_reviewer_encoded', 'company', 'text',\n",
      "       'text_processed', 'text_length', 'text_word_length', 'Sentiment_Blob',\n",
      "       'Sentiment_Blob_cat', 'Sentiment_VADER', 'Sentiment_VADER_cat',\n",
      "       'subject', 'subject_processed', 'subject_length', 'subject_word_length',\n",
      "       'answer', 'answer_processed', 'answered_encoded', 'date_of_experience',\n",
      "       'date_posted', 'local_date_posted', 'month_local', 'local_hour',\n",
      "       'time_of_day', 'day_of_week_posted', 'day_type',\n",
      "       'days_between_experience_and_post', 'review_time',\n",
      "       'review_time_encoded'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64205 entries, 0 to 64413\n",
      "Data columns (total 34 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   rating                            64205 non-null  int64         \n",
      " 1   location                          64205 non-null  object        \n",
      " 2   username                          64205 non-null  object        \n",
      " 3   number_reviews                    64205 non-null  int64         \n",
      " 4   verification                      64205 non-null  object        \n",
      " 5   repeat_reviewer                   64205 non-null  object        \n",
      " 6   repeat_reviewer_encoded           64205 non-null  int64         \n",
      " 7   company                           64205 non-null  object        \n",
      " 8   text                              64205 non-null  object        \n",
      " 9   text_processed                    64205 non-null  object        \n",
      " 10  text_length                       64205 non-null  int64         \n",
      " 11  text_word_length                  64205 non-null  int64         \n",
      " 12  Sentiment_Blob                    64205 non-null  float64       \n",
      " 13  Sentiment_Blob_cat                64205 non-null  float64       \n",
      " 14  Sentiment_VADER                   64205 non-null  float64       \n",
      " 15  Sentiment_VADER_cat               64205 non-null  int64         \n",
      " 16  subject                           64205 non-null  object        \n",
      " 17  subject_processed                 64205 non-null  object        \n",
      " 18  subject_length                    64205 non-null  int64         \n",
      " 19  subject_word_length               64205 non-null  int64         \n",
      " 20  answer                            64205 non-null  object        \n",
      " 21  answer_processed                  64205 non-null  object        \n",
      " 22  answered_encoded                  64205 non-null  int64         \n",
      " 23  date_of_experience                64205 non-null  datetime64[ns]\n",
      " 24  date_posted                       64205 non-null  datetime64[ns]\n",
      " 25  local_date_posted                 64205 non-null  datetime64[ns]\n",
      " 26  month_local                       64205 non-null  int64         \n",
      " 27  local_hour                        64205 non-null  int64         \n",
      " 28  time_of_day                       64205 non-null  object        \n",
      " 29  day_of_week_posted                64205 non-null  int64         \n",
      " 30  day_type                          64205 non-null  object        \n",
      " 31  days_between_experience_and_post  64205 non-null  int64         \n",
      " 32  review_time                       64205 non-null  object        \n",
      " 33  review_time_encoded               64205 non-null  int64         \n",
      "dtypes: datetime64[ns](3), float64(3), int64(14), object(14)\n",
      "memory usage: 17.1+ MB\n",
      "None\n",
      "The Trustpilot dataset has  34 columns\n",
      "The Trustpilot dataset has  64205 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>username</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>verification</th>\n",
       "      <th>repeat_reviewer</th>\n",
       "      <th>repeat_reviewer_encoded</th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_word_length</th>\n",
       "      <th>Sentiment_Blob</th>\n",
       "      <th>Sentiment_Blob_cat</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Sentiment_VADER_cat</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_processed</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>subject_word_length</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_processed</th>\n",
       "      <th>answered_encoded</th>\n",
       "      <th>date_of_experience</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>local_date_posted</th>\n",
       "      <th>month_local</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_week_posted</th>\n",
       "      <th>day_type</th>\n",
       "      <th>days_between_experience_and_post</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_time_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Rob Crane</td>\n",
       "      <td>2</td>\n",
       "      <td>Redirected</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>The company rep I worked with made my transact...</td>\n",
       "      <td>company rep worked made transaction smooth qui...</td>\n",
       "      <td>110</td>\n",
       "      <td>15</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>4</td>\n",
       "      <td>The company rep I worked with made myâ€¦</td>\n",
       "      <td>company rep worked made</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>2024-10-23 04:17:44</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>129</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Pat Anderson</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I highly recommend using Flashbay. Immediately...</td>\n",
       "      <td>highly recommend using flashbay immediately or...</td>\n",
       "      <td>202</td>\n",
       "      <td>26</td>\n",
       "      <td>0.345417</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>5</td>\n",
       "      <td>I highly recommend using Flashbay</td>\n",
       "      <td>highly recommend using flashbay</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>2024-10-16 19:34:05</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>2</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>CZ</td>\n",
       "      <td>Margarita Orlova</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had the pleasure of working with Shelby Gibs...</td>\n",
       "      <td>pleasure working shelby gibson large order nee...</td>\n",
       "      <td>175</td>\n",
       "      <td>24</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>5</td>\n",
       "      <td>Great customer service</td>\n",
       "      <td>great customer service</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>2024-10-17 10:27:44</td>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>3</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>7</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Paola Rivas</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had a fantastic experience with Brian Truong...</td>\n",
       "      <td>fantastic experience brian truong attentive tr...</td>\n",
       "      <td>122</td>\n",
       "      <td>14</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>5</td>\n",
       "      <td>Outstanding Support and Attentive Service</td>\n",
       "      <td>outstanding support attentive service</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>2024-10-21 22:38:50</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Fiona Mckelvey Keenan</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>My number-one go-to for computer accessories. ...</td>\n",
       "      <td>numberone goto computer accessories rachel sup...</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>5</td>\n",
       "      <td>My number-one go-to for computerâ€¦</td>\n",
       "      <td>numberone goto computer</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-11</td>\n",
       "      <td>2024-10-23 04:09:05</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>103</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating location               username  number_reviews  verification  \\\n",
       "0       5       CA              Rob Crane               2    Redirected   \n",
       "1       5       US           Pat Anderson               1      Verified   \n",
       "2       5       CZ       Margarita Orlova               1      Verified   \n",
       "3       5       US            Paola Rivas               1      Verified   \n",
       "4       5       CA  Fiona Mckelvey Keenan               3  Not Verified   \n",
       "\n",
       "  repeat_reviewer  repeat_reviewer_encoded   company  \\\n",
       "0          repeat                        1  Flashbay   \n",
       "1        one-time                        0  Flashbay   \n",
       "2        one-time                        0  Flashbay   \n",
       "3        one-time                        0  Flashbay   \n",
       "4          repeat                        1  Flashbay   \n",
       "\n",
       "                                                text  \\\n",
       "0  The company rep I worked with made my transact...   \n",
       "1  I highly recommend using Flashbay. Immediately...   \n",
       "2  I had the pleasure of working with Shelby Gibs...   \n",
       "3  I had a fantastic experience with Brian Truong...   \n",
       "4  My number-one go-to for computer accessories. ...   \n",
       "\n",
       "                                      text_processed  text_length  \\\n",
       "0  company rep worked made transaction smooth qui...          110   \n",
       "1  highly recommend using flashbay immediately or...          202   \n",
       "2  pleasure working shelby gibson large order nee...          175   \n",
       "3  fantastic experience brian truong attentive tr...          122   \n",
       "4  numberone goto computer accessories rachel sup...          155   \n",
       "\n",
       "   text_word_length  Sentiment_Blob  Sentiment_Blob_cat  Sentiment_VADER  \\\n",
       "0                15        0.311111                 4.0           0.4215   \n",
       "1                26        0.345417                 4.0           0.6233   \n",
       "2                24        0.320223                 4.0           0.9643   \n",
       "3                14        0.600000                 4.0           0.9169   \n",
       "4                18        0.386667                 4.0           0.8553   \n",
       "\n",
       "   Sentiment_VADER_cat                                    subject  \\\n",
       "0                    4     The company rep I worked with made myâ€¦   \n",
       "1                    5          I highly recommend using Flashbay   \n",
       "2                    5                     Great customer service   \n",
       "3                    5  Outstanding Support and Attentive Service   \n",
       "4                    5          My number-one go-to for computerâ€¦   \n",
       "\n",
       "                       subject_processed  subject_length  subject_word_length  \\\n",
       "0                company rep worked made              23                    4   \n",
       "1        highly recommend using flashbay              31                    4   \n",
       "2                 great customer service              22                    3   \n",
       "3  outstanding support attentive service              37                    4   \n",
       "4                numberone goto computer              23                    3   \n",
       "\n",
       "  answer answer_processed  answered_encoded date_of_experience  \\\n",
       "0      0                0                 0         2024-06-15   \n",
       "1      0                0                 0         2024-10-16   \n",
       "2      0                0                 0         2024-10-10   \n",
       "3      0                0                 0         2024-10-21   \n",
       "4      0                0                 0         2024-07-11   \n",
       "\n",
       "          date_posted local_date_posted  month_local  local_hour  \\\n",
       "0 2024-10-23 04:17:44        2024-10-22           10          21   \n",
       "1 2024-10-16 19:34:05        2024-10-16           10          12   \n",
       "2 2024-10-17 10:27:44        2024-10-17           10          10   \n",
       "3 2024-10-21 22:38:50        2024-10-21           10          15   \n",
       "4 2024-10-23 04:09:05        2024-10-22           10          21   \n",
       "\n",
       "      time_of_day  day_of_week_posted      day_type  \\\n",
       "0         Evening                   1  Business Day   \n",
       "1  Business Hours                   2  Business Day   \n",
       "2  Business Hours                   3  Business Day   \n",
       "3  Business Hours                   0  Business Day   \n",
       "4         Evening                   1  Business Day   \n",
       "\n",
       "   days_between_experience_and_post   review_time  review_time_encoded  \n",
       "0                               129   late_review                    0  \n",
       "1                                 0  quick_review                    1  \n",
       "2                                 7   late_review                    0  \n",
       "3                                 0  quick_review                    1  \n",
       "4                               103   late_review                    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Inspecting final output \n",
    "\n",
    "print(df_trustpilot.columns)\n",
    "print(df_trustpilot.info())\n",
    "print(\"The Trustpilot dataset has \", df_trustpilot.shape[1], \"columns\")\n",
    "print(\"The Trustpilot dataset has \", df_trustpilot.shape[0], \"rows\")\n",
    "display(df_trustpilot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DataFrame exported to data/data_trustpilot_3.csv\n",
      "Training set exported to data/train_trustpilot_3.csv\n",
      "Test set exported to data/test_trustpilot_3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "csv_path = 'data/data_trustpilot_3.csv'\n",
    "df_trustpilot.to_csv(csv_path, index=False)\n",
    "print(f\"Full DataFrame exported to {csv_path}\")\n",
    "\n",
    "train_path = 'data/train_trustpilot_3.csv'\n",
    "test_path = 'data/test_trustpilot_3.csv'\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Training set exported to {train_path}\")\n",
    "print(f\"Test set exported to {test_path}\")\n",
    "\n",
    "X_train_tfidf = np.load('data/X_train_tfidf.npy')\n",
    "X_test_tfidf = np.load('data/X_test_tfidf.npy')\n",
    "feature_names = np.load('data/tfidf_features.npy', allow_pickle=True)\n",
    "\n",
    "X_train_bow = np.load('data/X_train_bow.npy')\n",
    "X_test_bow = np.load('data/X_test_bow.npy')\n",
    "bow_features = np.load('data/bow_features.npy', allow_pickle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
