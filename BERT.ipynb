{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.7-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.0-cp312-cp312-win_amd64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.0 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.6/10.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/203.0 MB 6.1 MB/s eta 0:00:34\n",
      "    --------------------------------------- 2.6/203.0 MB 6.6 MB/s eta 0:00:31\n",
      "    --------------------------------------- 3.9/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 5.2/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 6.6/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 8.1/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 9.4/203.0 MB 6.5 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 10.7/203.0 MB 6.5 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 12.1/203.0 MB 6.4 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 13.4/203.0 MB 6.5 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 14.7/203.0 MB 6.5 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 16.0/203.0 MB 6.5 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 17.3/203.0 MB 6.5 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 18.6/203.0 MB 6.5 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 19.9/203.0 MB 6.5 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 21.5/203.0 MB 6.4 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 22.8/203.0 MB 6.4 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 24.1/203.0 MB 6.4 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 25.4/203.0 MB 6.4 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 26.7/203.0 MB 6.4 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 28.0/203.0 MB 6.4 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 29.4/203.0 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 30.7/203.0 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 32.0/203.0 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 33.6/203.0 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 34.9/203.0 MB 6.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 36.2/203.0 MB 6.4 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 37.5/203.0 MB 6.4 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 38.8/203.0 MB 6.4 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 40.1/203.0 MB 6.4 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 41.7/203.0 MB 6.4 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 43.0/203.0 MB 6.4 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 44.3/203.0 MB 6.4 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 45.6/203.0 MB 6.4 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 46.9/203.0 MB 6.4 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 48.2/203.0 MB 6.4 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 49.5/203.0 MB 6.4 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 50.9/203.0 MB 6.4 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 52.2/203.0 MB 6.4 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 53.5/203.0 MB 6.4 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 54.8/203.0 MB 6.4 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 56.1/203.0 MB 6.4 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 57.4/203.0 MB 6.4 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 58.7/203.0 MB 6.4 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 60.3/203.0 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 61.6/203.0 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 62.9/203.0 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 64.2/203.0 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 65.5/203.0 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 67.1/203.0 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 68.4/203.0 MB 6.4 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 69.7/203.0 MB 6.4 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 71.0/203.0 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 72.6/203.0 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 73.9/203.0 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 75.2/203.0 MB 6.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 76.5/203.0 MB 6.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 77.9/203.0 MB 6.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 79.2/203.0 MB 6.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 80.5/203.0 MB 6.4 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 81.8/203.0 MB 6.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 83.1/203.0 MB 6.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 84.7/203.0 MB 6.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 86.0/203.0 MB 6.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 87.3/203.0 MB 6.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 88.9/203.0 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 90.2/203.0 MB 6.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 91.5/203.0 MB 6.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 92.8/203.0 MB 6.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 94.1/203.0 MB 6.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 95.4/203.0 MB 6.4 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 96.7/203.0 MB 6.4 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 98.0/203.0 MB 6.4 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 99.4/203.0 MB 6.4 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 100.9/203.0 MB 6.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 102.2/203.0 MB 6.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 103.5/203.0 MB 6.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 104.9/203.0 MB 6.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 106.2/203.0 MB 6.4 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 107.5/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 108.8/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 110.1/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 111.4/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 112.7/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 114.0/203.0 MB 6.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 115.3/203.0 MB 6.4 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 116.7/203.0 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 118.0/203.0 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 119.3/203.0 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 120.6/203.0 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 121.9/203.0 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 123.5/203.0 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 124.8/203.0 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 126.1/203.0 MB 6.4 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 127.4/203.0 MB 6.4 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 129.0/203.0 MB 6.4 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 130.3/203.0 MB 6.4 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 131.6/203.0 MB 6.4 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 132.9/203.0 MB 6.4 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 134.5/203.0 MB 6.4 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 135.8/203.0 MB 6.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 137.1/203.0 MB 6.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 138.4/203.0 MB 6.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 139.7/203.0 MB 6.4 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 141.0/203.0 MB 6.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 142.3/203.0 MB 6.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 143.7/203.0 MB 6.4 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 145.2/203.0 MB 6.4 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 146.5/203.0 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 147.8/203.0 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 149.2/203.0 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 150.5/203.0 MB 6.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 151.8/203.0 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 153.4/203.0 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 154.7/203.0 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 156.0/203.0 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 157.3/203.0 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 158.9/203.0 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 160.2/203.0 MB 6.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 161.5/203.0 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 162.8/203.0 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 164.1/203.0 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 165.4/203.0 MB 6.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 166.7/203.0 MB 6.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 168.0/203.0 MB 6.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 169.3/203.0 MB 6.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 170.7/203.0 MB 6.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 172.2/203.0 MB 6.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 173.5/203.0 MB 6.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 174.9/203.0 MB 6.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 176.2/203.0 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 177.7/203.0 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.0/203.0 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.4/203.0 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 181.9/203.0 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 183.2/203.0 MB 6.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.5/203.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.9/203.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 187.2/203.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.7/203.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 190.1/203.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.4/203.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 192.7/203.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.2/203.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.6/203.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.9/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.8/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.1/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.4/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/6.2 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.9/6.2 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.7-cp312-cp312-win_amd64.whl (436 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/25.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 6.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.9/25.1 MB 6.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.2/25.1 MB 6.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.5/25.1 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.9/25.1 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.2/25.1 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.5/25.1 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.8/25.1 MB 6.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.1/25.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.7/25.1 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.0/25.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.6/25.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.9/25.1 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.2/25.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/25.1 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.0-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: mpmath, xxhash, sympy, safetensors, pyarrow, propcache, networkx, multidict, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, torch, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 propcache-0.2.0 pyarrow-18.0.0 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.3 xxhash-3.5.0 yarl-1.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\.conda\\envs\\supply_chain\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\Users\\Admin\\.conda\\envs\\supply_chain\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "---\n",
      "Name: accelerate\n",
      "Version: 1.1.1\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: c:\\Users\\Admin\\.conda\\envs\\supply_chain\\Lib\\site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n",
      "---\n",
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\Users\\Admin\\.conda\\envs\\supply_chain\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
      "Required-by: accelerate\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\": Expected package name at the start of dependency specifier\n",
      "    'accelerate\n",
      "    ^\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\.conda\\envs\\supply_chain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\.conda\\envs\\supply_chain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>username</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>verification</th>\n",
       "      <th>repeat_reviewer</th>\n",
       "      <th>repeat_reviewer_encoded</th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>...</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>local_date_posted</th>\n",
       "      <th>month_local</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_week_posted</th>\n",
       "      <th>day_type</th>\n",
       "      <th>days_between_experience_and_post</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_time_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Rob Crane</td>\n",
       "      <td>2</td>\n",
       "      <td>Redirected</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>The company rep I worked with made my transact...</td>\n",
       "      <td>company rep worked made transaction smooth qui...</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-23 04:17:44</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>129</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Pat Anderson</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I highly recommend using Flashbay. Immediately...</td>\n",
       "      <td>highly recommend using flashbay immediately or...</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-16 19:34:05</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>2</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>CZ</td>\n",
       "      <td>Margarita Orlova</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had the pleasure of working with Shelby Gibs...</td>\n",
       "      <td>pleasure working shelby gibson large order nee...</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-17 10:27:44</td>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>3</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>7</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>Paola Rivas</td>\n",
       "      <td>1</td>\n",
       "      <td>Verified</td>\n",
       "      <td>one-time</td>\n",
       "      <td>0</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>I had a fantastic experience with Brian Truong...</td>\n",
       "      <td>fantastic experience brian truong attentive tr...</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-21 22:38:50</td>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Business Hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>0</td>\n",
       "      <td>quick_review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>Fiona Mckelvey Keenan</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>repeat</td>\n",
       "      <td>1</td>\n",
       "      <td>Flashbay</td>\n",
       "      <td>My number-one go-to for computer accessories. ...</td>\n",
       "      <td>numberone goto computer accessories rachel sup...</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-23 04:09:05</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>103</td>\n",
       "      <td>late_review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating location               username  number_reviews  verification  \\\n",
       "0       5       CA              Rob Crane               2    Redirected   \n",
       "1       5       US           Pat Anderson               1      Verified   \n",
       "2       5       CZ       Margarita Orlova               1      Verified   \n",
       "3       5       US            Paola Rivas               1      Verified   \n",
       "4       5       CA  Fiona Mckelvey Keenan               3  Not Verified   \n",
       "\n",
       "  repeat_reviewer  repeat_reviewer_encoded   company  \\\n",
       "0          repeat                        1  Flashbay   \n",
       "1        one-time                        0  Flashbay   \n",
       "2        one-time                        0  Flashbay   \n",
       "3        one-time                        0  Flashbay   \n",
       "4          repeat                        1  Flashbay   \n",
       "\n",
       "                                                text  \\\n",
       "0  The company rep I worked with made my transact...   \n",
       "1  I highly recommend using Flashbay. Immediately...   \n",
       "2  I had the pleasure of working with Shelby Gibs...   \n",
       "3  I had a fantastic experience with Brian Truong...   \n",
       "4  My number-one go-to for computer accessories. ...   \n",
       "\n",
       "                                      text_processed  ...  \\\n",
       "0  company rep worked made transaction smooth qui...  ...   \n",
       "1  highly recommend using flashbay immediately or...  ...   \n",
       "2  pleasure working shelby gibson large order nee...  ...   \n",
       "3  fantastic experience brian truong attentive tr...  ...   \n",
       "4  numberone goto computer accessories rachel sup...  ...   \n",
       "\n",
       "           date_posted  local_date_posted  month_local  local_hour  \\\n",
       "0  2024-10-23 04:17:44         2024-10-22           10          21   \n",
       "1  2024-10-16 19:34:05         2024-10-16           10          12   \n",
       "2  2024-10-17 10:27:44         2024-10-17           10          10   \n",
       "3  2024-10-21 22:38:50         2024-10-21           10          15   \n",
       "4  2024-10-23 04:09:05         2024-10-22           10          21   \n",
       "\n",
       "      time_of_day  day_of_week_posted      day_type  \\\n",
       "0         Evening                   1  Business Day   \n",
       "1  Business Hours                   2  Business Day   \n",
       "2  Business Hours                   3  Business Day   \n",
       "3  Business Hours                   0  Business Day   \n",
       "4         Evening                   1  Business Day   \n",
       "\n",
       "  days_between_experience_and_post   review_time  review_time_encoded  \n",
       "0                              129   late_review                    0  \n",
       "1                                0  quick_review                    1  \n",
       "2                                7   late_review                    0  \n",
       "3                                0  quick_review                    1  \n",
       "4                              103   late_review                    0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"data\\data_trustpilot.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readjustment to make it fit in the model \n",
    "df['rating'] = df['rating'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9796\\3313736649.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "                                        \n",
      "  0%|          | 0/9663 [04:05<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5118, 'grad_norm': 6.097047328948975, 'learning_rate': 1.997930249404947e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [07:17<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3196, 'grad_norm': 4.611196994781494, 'learning_rate': 1.9958604988098936e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [10:26<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3968, 'grad_norm': 5.957694053649902, 'learning_rate': 1.9937907482148403e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [13:35<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0944, 'grad_norm': 6.804468631744385, 'learning_rate': 1.991720997619787e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [16:42<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0166, 'grad_norm': 5.423838138580322, 'learning_rate': 1.9896512470247337e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [19:41<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0151, 'grad_norm': 6.561586856842041, 'learning_rate': 1.9875814964296804e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [22:41<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9256, 'grad_norm': 5.231472969055176, 'learning_rate': 1.985511745834627e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [25:40<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8713, 'grad_norm': 6.622488975524902, 'learning_rate': 1.9834419952395738e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [28:39<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9067, 'grad_norm': 7.720926284790039, 'learning_rate': 1.9813722446445205e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [31:51<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.809, 'grad_norm': 10.973278045654297, 'learning_rate': 1.9793024940494672e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [35:11<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7496, 'grad_norm': 3.6657865047454834, 'learning_rate': 1.977232743454414e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [38:28<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.776, 'grad_norm': 4.619821071624756, 'learning_rate': 1.9751629928593606e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [41:56<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8392, 'grad_norm': 8.294193267822266, 'learning_rate': 1.9730932422643073e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \n",
      "  0%|          | 0/9663 [45:30<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7373, 'grad_norm': 12.684285163879395, 'learning_rate': 1.971023491669254e-05, 'epoch': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Select the column to use as input \n",
    "input_column = 'text_processed'  \n",
    "\n",
    "# Tokenization and Dataset Preparation\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        text = row[input_column]\n",
    "        rating = row['rating']\n",
    "        tokens = self.tokenizer(\n",
    "            text, \n",
    "            max_length=self.max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': tokens['input_ids'].squeeze(),\n",
    "            'attention_mask': tokens['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(rating, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "\n",
    "# Prepare Dataset\n",
    "max_length = 128\n",
    "dataset = ReviewDataset(df, tokenizer, max_length)\n",
    "\n",
    "# Split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = ReviewDataset(train_df, tokenizer, max_length)\n",
    "test_dataset = ReviewDataset(test_df, tokenizer, max_length)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Test Results: {results}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supply_chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
